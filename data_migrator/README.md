# Как обновить данные на предпроде до состояния прода:

1. Открываем терминал, заходим на четвёртую ноду и запускаем команду для просмотра логов,
где <table_name> - название нашей таблицы, например, name1
// Это норма что там ничего ещё нет

// Логи затираются после каждого следующего вызова скрипта с данной таблицей,
// то есть логи name1 будут живы, если после них выполнялось только обновление name2,
// но сотрутся при следующей попытке перелить name1 (Капитан Очевидность)

```
ssh user@hostname
ls /tmp/data_migrator/
tail -f /tmp/data_migrator/<table_name>.log
```

2. Открываем второй терминал и заходим на ноду
```
ssh user@hostname
```

3. Открываем screen
```
screen
```

4. Заходим в папочку с тулзой
```
cd /usr/bin/data-migrator
```

5. Запускаем тулзу 
```
./data_migrator.sh
```

6. Для переливки таблицы name3, пишем в файлик dt даты, которые необходимо перелить.  
В файл (./dt) помещаем список дат (по одной на строку), которые нужно залить на предпрод, в формате:
```
2017-06-25
2017-06-26
```
// Посмотреть текущий список партиций по датам: 
```
hadoop fs -ls /data/database_name.db/name3
```

7. Выбираем таблицу, которую собираемся переливать, затем ещё раз жамкаем "ОК"

8. Наслаждаемся логами в первом терминальчике
Далее всё пройдёт в автоматическом режиме.
Удаление дубликатов таблицы name2 запустится сразу после заливки и 
добавления в hive данной таблицы.

Чтобы поискать по логам, можно воспользоваться командой less в директории с логами data_migrator'а:
```
less data_migrator.log
```
А затем набрать, / и то что мы хотим найти, например, /Удаление дубликатов

В файл логов пишутся как логи YARN'а и Hive, так и логи нашей утилиты. 
Наши логи начинаются со следующих символов:
- ">>>" (Начало выполнения функции, например, ">>> Добавление партиций в hive")
- "<<<" (Завершение работы функции, например, "<<< Добавление партиций в hive завершено")
- "->" (Информация о текущем состоянии функции, например, "Добавление партиции 2017-01-01 в hive")

*// AlreadyExistsException в Hive означает, что данные уже были ранее добавлены в Hive, и их добавление не нужно
